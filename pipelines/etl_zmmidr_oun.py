import sys, os, io
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


import os
import re
import shutil
import pandas as pd
from pathlib import Path
from collections import defaultdict
from ETL_SAP.common.loader import *
from ETL_SAP.common.config import get_sql_engine
from datetime import datetime
from sqlalchemy.types import VARCHAR, NVARCHAR, DECIMAL, INTEGER, Date, DateTime
from ETL_SAP.sap_scripts.downloader_zmmidr_oun import download_zmmidr_OUn
from ETL_SAP.pipelines.etl_utils import *
from dotenv import load_dotenv

from ETL_SAP.sap_scripts.downloader_zmmidr_bun import download_zmmidr_BUn
from ETL_SAP.pipelines.etl_zmmidr_bun import run_etl_zmmidr_BUn

load_dotenv()

def load_zmmidr_file(filepath, dc):
    df = pd.read_excel(filepath, dtype={'Article No': str, 'MCH': str})
    df.drop(df.index[-1], inplace=True)  # åˆªé™¤åˆè¨ˆåˆ—
    df['Article No'] = df['Article No'].str.lstrip('0')
    df = df.rename(columns={'Article No': 'Article'})
    df.insert(0, 'DC', dc)

    return df

def run_etl_zmmidr_OUn(folder_path):
    print("ğŸ”¹ é–‹å§‹æ¸…ç† Zmmidr_OUn æª”æ¡ˆ...")
    
    # éæ­·æ‰€æœ‰ Excel æª”æ¡ˆï¼Œæ ¼å¼å¦‚ Zmmidr_106_9801_06012025.xlsx
    file_pattern = re.compile(r'Zmmidr_oun_(\d{3})_(\d{4})_\d{8}\.xlsx')
    dept_dfs = defaultdict(list)
    processed_dir = os.path.join(folder_path, "processed")
    os.makedirs(processed_dir, exist_ok=True)

    for fname in os.listdir(folder_path):
        m = file_pattern.match(fname)
        if not m:
            continue
        dept, dc = m.groups()
        full_path = os.path.join(folder_path, fname)
        df = load_zmmidr_file(full_path, dc)
        dept_dfs[dept].append(df)

    # å„ Dept å…ˆ concatï¼Œè‡ªæˆä¸€å¼µï¼›å† concat å…¨éƒ¨
    combined_all = [
        pd.concat(df_list, ignore_index=True)
        for df_list in dept_dfs.values()
    ]

    if not combined_all:
        print("âš ï¸ æ²’æœ‰ä»»ä½•å¯åˆä½µçš„è³‡æ–™ï¼Œè·³é Zmmidr_OUn ä¸Šå‚³æµç¨‹")
        return 

    df_all = pd.concat(combined_all, ignore_index=True)

    print(f"âœ… åˆä½µå®Œæˆï¼Œå…± {len(df_all)} ç­†")

    # æ•¸å­—æ¸…æ´—
    df_all['Unrestricted-Use Stock'] = df_all['Unrestricted-Use Stock'].apply(clean_number)
    df_all['On order Stock'] = df_all['On order Stock'].apply(clean_number)
    df_all.insert(0, 'Date', datetime.today().date())

    if df_all.duplicated(subset=['Date', 'DC', 'Article']).any():
        duplicate_count = len(df_all.duplicated(subset=['Date', 'DC', 'Article']).sum())
        print(f" {duplicate_count} duplicates found, have been removed.")
        print(df_all[df_all.duplicated(subset=['Date', 'DC', 'Article'])])
        df_all = df_all.drop_duplicates(subset=['Date', 'DC', 'Article'], keep='last').reset_index(drop=True)

    df_all.to_excel(os.path.join(folder_path, f"df_Zmmidr_OUn_{datetime.today().strftime('%m%d%Y')}.xlsx"), index=False)
    df_all.to_excel(rf"\\TAWASHARE2\Replenishment_Data\Jimmy\Zmmidr\df_Zmmidr_OUn_{datetime.today().strftime('%m%d%Y')}.xlsx", index=False)
    print(f"å·²åŒ¯å‡ºæ‰€æœ‰éƒ¨é–€çš„ df_Zmmidr_OUn_date.xlsx")
    Process_Dry_Zmmidr(df_all)
   

    # ä¸Šå‚³è‡³ SQL Server
    print(f"ğŸ”¹ é–‹å§‹ä¸Šå‚³ Zmmidr_oun è³‡æ–™åˆ° {os.getenv("SQL_DB")}...")
    engine = get_sql_engine()
    column_types = {
    'Date': Date,     
    'DC': NVARCHAR(10),
    'Article': NVARCHAR(20),
    'MCH': NVARCHAR(50),                         
    'Pack size': NVARCHAR(50),
    'Unit': NVARCHAR(10),                 
    'D/C MAP': DECIMAL(14, 6),                 
    'Unrestricted-Use Stock': DECIMAL(14, 6),       # åº«å­˜é‡ï¼ˆæ•¸é‡ï¼‰
    'Allocation Qty': DECIMAL(14, 6),               # åˆ†é…é‡ï¼ˆæ•¸é‡ï¼‰
    'On order Stock': DECIMAL(14, 6),               # å·²è¨‚è³¼åº«å­˜ï¼ˆæ•¸é‡ï¼‰
    'Unrestricted Stock Value': DECIMAL(14, 6),# åº«å­˜åƒ¹å€¼ï¼ˆé«˜é‡‘é¡ï¼‰
    'PTD MVMT': DECIMAL(14, 6),                     # æœ¬æœŸç§»å‹•é‡
    'YTD MVMT': DECIMAL(14, 6),                     # å¹´ç´¯è¨ˆç§»å‹•é‡
    }  


    # ä¸Šå‚³è‡³ Zmmidr - replace

    upsert_batch(
        df=df_all,
        target_table=os.getenv("TABLE_ZMMIDR_OUn"),
        unique_keys=["DC", "Article", "Date"],
        column_types=column_types
    )
    
    # upload_to_sql(df_all, os.getenv("TABLE_ZMMIDR_OUn"), column_types, 'replace')

    # ---------- ç§»å‹•åˆ° processed ----------
    kill_excel()
    time.sleep(2)
    for filename in os.listdir(folder_path):
        if "Zmmidr_" in filename:
            src_path = os.path.join(folder_path, filename)
            if os.path.isfile(src_path):
                name, ext = os.path.splitext(filename)
                new_name = f"{name}_{ext}"
                dest_path = os.path.join(processed_dir, new_name)
                shutil.move(src_path, dest_path)
                print(f"Moved: {filename} â†’ {new_name}")

    print("å®Œæˆ Zmmidr_OUn ä¸Šå‚³æµç¨‹")




def Process_Dry_Zmmidr(df):
    # df = pd.read_excel(os.path.join(folder_path, "df_Zmmidr_all.xlsx"))
    df = df.copy()
    # df['Dept'] = df['MCH'].astype(str).str[:3]
    # df = df[df['Dept']=='106']
    # df.drop(columns='Dept', inplace=True)
    df.dropna(subset='Article', inplace=True)
    df = df[['DC', 'Article', 'Unrestricted-Use Stock', 'On order Stock']]

    df_SCA = df[df['DC'].astype(str).isin(['9891', '9801'])]
    df_SCA = df_SCA.groupby("Article", as_index=False, observed=True).agg({
        'DC':'first',
        'Unrestricted-Use Stock':'sum',
        'On order Stock':'sum'
    })
    df_SCA['DC']='9891'
    print("length of 9891: ", len(df[df['DC']=='9891']))
    print("length of 9890: ", len(df[df['DC']=='9801']))
    print("length of SCA: ", len(df_SCA))


    df_EC = df[df['DC'].astype(str).isin(['9790', '9901'])]
    df_EC = df_EC.groupby("Article", as_index=False, observed=True).agg({
        'DC':'first',
        'Unrestricted-Use Stock':'sum',
        'On order Stock':'sum'
    })
    df_EC['DC']='9790'

    print("length of 9790: ", len(df[df['DC']=='9790']))
    print("length of 9901: ", len(df[df['DC']=='9901']))
    print("length of EC: ", len(df_EC))

    df_NCA = df[df['DC'].astype(str).isin(['9900'])]
    df_9793 = df[df['DC'].astype(str).isin(['9793'])]


    df_all = pd.concat([df_SCA, df_NCA, df_EC, df_9793], ignore_index=True)
    df_all.insert(0, 'Article NoDC', df_all['DC'].astype(str) + df_all['Article'].astype(str))

    current_inv_fp = os.getenv("current_inv_fp")
    history_inv_fp = os.getenv("history_inv_fp")
    
    df_all.to_excel(os.path.join(current_inv_fp, "df_Zmmidr_OUn.xlsx"), index=False)
    df_all.to_excel(os.path.join(history_inv_fp, f"df_Zmmidr_OUn_{datetime.today().date().strftime('%m%d%Y')}.xlsx"), index=False)
    df_all.to_excel(r"\\TAWASHARE2\Replenishment_Data\Jimmy\Zmmidr\df_Zmmidr_OUn.xlsx", index=False)
    print(f"å·²åŒ¯å‡ºåˆä½µåº«å­˜ Zmmidr è‡³ {current_inv_fp} åŠ {history_inv_fp} åŠ å…±äº«è³‡æ–™å¤¾")


if __name__ == "__main__":

    download_zmmidr_OUn(os.getenv("EXPORT_DIR_ZMMIDR_OUn"))
    run_etl_zmmidr_OUn(os.getenv("EXPORT_DIR_ZMMIDR_OUn"))


    
    
    





    # # åˆä½µ EC å€åŸŸ code =======================================================
    # dept_dfs = defaultdict(list)

    # for file in os.listdir(folder_path):
    #     match = file_pattern.match(file)
    #     if match:
    #         dept, dc = match.groups()
    #         full_path = os.path.join(folder_path, file)
    #         df = load_zmmidr_file(full_path, dc)
    #         dept_dfs[dept].append((dc, df))

    # combined_all = []
    # for dept, dc_df_list in dept_dfs.items():
    #     dfs = {dc: df for dc, df in dc_df_list}

    #     # åˆä½µ EC å€‰åº«ï¼š9901 + 9902 + 9905
    #     ec_sources = [dfs[dc] for dc in ['9901', '9902', '9905'] if dc in dfs]
    #     if ec_sources:
    #         df_ec = pd.concat(ec_sources, ignore_index=True)
    #         df_ec = df_ec.groupby("Article", as_index=False).agg({
    #             'DC': 'first',
    #             'Article': 'first',
    #             'MCH': 'first',
    #             'Dept': 'first',
    #             'Article Description': 'first',
    #             'Article Description.1': 'first',
    #             'Pack size': 'first',
    #             'D/C MAP': 'first',
    #             'Unrestricted-Use Stock': 'sum',
    #             'Allocation Qty': 'sum',
    #             'On order Stock': 'sum',
    #             'Unrestricted Stock Value': 'sum',
    #             'PTD MVMT': 'sum', 
    #             'YTD MVMT': 'sum', 
    #             'SCA Assortment': 'first', 
    #             'Assortment grade': 'first', 
    #             'Asrt.Grade Description': 'first', 
    #         })
    #         df_ec['DC'] = 'EC'
    #     else:
    #         df_ec = pd.DataFrame()

    #     # åˆä½µé€™å€‹éƒ¨é–€çš„æ‰€æœ‰å€‰åº«
    #     dfs_list = [dfs[dc] for dc in ['9801', '9900'] if dc in dfs]
    #     if not df_ec.empty:
    #         dfs_list.append(df_ec)

    #     if not dfs_list:
    #         continue

    #     df_dept_combined = pd.concat(dfs_list, ignore_index=True)
    #     combined_all.append(df_dept_combined)

    # # åˆä½µæ‰€æœ‰éƒ¨é–€çµæœ
    # df_all = pd.concat(combined_all, ignore_index=True)